## Neural Networks
Saw and amazing [video](https://www.youtube.com/watch?v=aircAruvnKk) by 3Blue1Brown. Where he introduces neural neyworks not as a black box but each neuron as a function which maps the input to the output.

Previously reserchers used to sigmoid function as an activation function which appraently gave poor performance nowadays most researchers use RELU.

The transformation in simple form in written by
a<sup>(1)</sup> = RELU(**W***a<sup>(0)</sup> + **B**)
where:
W = Weight Matrix
B = Bias matrix

Source:
https://www.youtube.com/watch?v=aircAruvnKk
